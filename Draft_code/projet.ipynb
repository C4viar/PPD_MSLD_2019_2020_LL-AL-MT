{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C4viar/PPD_MSLD_2019_2020_LL-AL-MT/blob/master/Draft_code/projet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ZqJzN4vZZK",
        "colab_type": "text"
      },
      "source": [
        "# Réplication de l'exemple GIT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvF_g7MU5sQw",
        "colab_type": "text"
      },
      "source": [
        "## Installation des packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edvb4dSeoD0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "4ded50c0-8c57-4a4e-d9cc-652b95cc5c80"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 31.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=9cc1bd554c55d64454ddbec0f8974ce0e55ff811ad986545a9e3fc57a15e76b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEsO0FTao_2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "170bb567-189f-4be1-d2e7-ee1d850dd9b1"
      },
      "source": [
        "! pip install torchvision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRR2FKEa2hqj",
        "colab_type": "text"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzDHUpGfZOdd",
        "colab_type": "text"
      },
      "source": [
        "1. Reproduire avec l’implémentation\n",
        "https://huggingface.co/transformers/model_doc/camembert.html\n",
        "les manipulations décrites dans https://github.com/pytorch/fairseq/tree/master/examples/camembert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBgE2pvxd3OB",
        "colab_type": "text"
      },
      "source": [
        "## CamemBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE3vTsynouCQ",
        "colab_type": "text"
      },
      "source": [
        "Rappel : Tous les types de modèles : https://huggingface.co/models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrCGiAgBBuJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install transformers;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmYfZW5vX4KO",
        "colab_type": "text"
      },
      "source": [
        "#### Fill mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGx-9wrQZ41s",
        "colab_type": "code",
        "outputId": "1676d7bc-853d-4f41-b815-e722ab483e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "from transformers import pipeline, CamembertModel, CamembertTokenizer, CamembertForMaskedLM, PreTrainedModel\n",
        "\n",
        "\n",
        "sentence_fillmask = \"\"\"Le camembert c'est <mask>\"\"\".lstrip()\n",
        "model_fillmask_str = \"camembert-base\"\n",
        "model_fillmask = CamembertForMaskedLM.from_pretrained(model_fillmask_str )\n",
        "tokenizer_fillmask = CamembertTokenizer.from_pretrained(model_fillmask_str )\n",
        "\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model = model_fillmask,\n",
        "    tokenizer = tokenizer_fillmask \n",
        "    )\n",
        "\n",
        "fill_mask(sentence_fillmask)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2072705626487732,\n",
              "  'sequence': \"<s> Le camembert c'est quoi</s>\",\n",
              "  'token': 484},\n",
              " {'score': 0.08772061765193939,\n",
              "  'sequence': \"<s> Le camembert c'est bon</s>\",\n",
              "  'token': 212},\n",
              " {'score': 0.05717896297574043,\n",
              "  'sequence': \"<s> Le camembert c'est délicieux</s>\",\n",
              "  'token': 7200},\n",
              " {'score': 0.05560891702771187,\n",
              "  'sequence': \"<s> Le camembert c'est...</s>\",\n",
              "  'token': 186},\n",
              " {'score': 0.05323265120387077,\n",
              "  'sequence': \"<s> Le camembert c'est :</s>\",\n",
              "  'token': 43}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJlubl3jBE6m",
        "colab_type": "text"
      },
      "source": [
        "#### Sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imQ9nbvhxF8u",
        "colab_type": "text"
      },
      "source": [
        "Indisponible avec Camembert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It4Id0s-BD-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import CamembertForTokenClassification\n",
        "\n",
        "sentence_sentiment = \"Le camembert c'est bon\"\n",
        "\n",
        "model_sentiment_str = \"\"\n",
        "model_sentiment = CamembertForSequenceClassification.from_pretrained(model_sentiment_str)\n",
        "tokenizer_sentiment = CamembertTokenizer.from_pretrained(model_sentiment_str )\n",
        "\n",
        "sentiment_analysis = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model = model_sentiment,\n",
        "    tokenizer = tokenizer_sentiment\n",
        "    )\n",
        "\n",
        "sentiment_analysis(sentence_sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V55psHqNz_2",
        "colab_type": "text"
      },
      "source": [
        "#### NER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_XxrSLmyAAz",
        "colab_type": "text"
      },
      "source": [
        "Indisponible avec Camembert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf0Jl_b-N6EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import CamembertForTokenClassification\n",
        "\n",
        "sentence_ner = \"Amar habite à Paris\"\n",
        "\n",
        "ner_model_str = ''\n",
        "ner_model = CamembertForTokenClassification.from_pretrained(ner_model_str)\n",
        "tokenizer_ner= CamembertTokenizer.from_pretrained(ner_model_str)\n",
        "\n",
        "ner = pipeline(\n",
        "    \"ner\",\n",
        "    model = ner_model,\n",
        "    tokenizer = tokenizer_ner\n",
        "    )\n",
        "\n",
        "ner(sentence_net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKjwmr34tZeV",
        "colab_type": "text"
      },
      "source": [
        "#### Question answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbojeRDMtWxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import CamembertForTokenClassification\n",
        "\n",
        "quest_model_str = ''\n",
        "quest_model = XXXXXXX.from_pretrained(quest_model_str)  # XXXXXXX à remplacer / ! \\\n",
        "tokenizer_quest= CamembertTokenizer.from_pretrained(quest_model_str)\n",
        "\n",
        "quest = pipeline(\n",
        "    \"question_answering\",\n",
        "    model = quest_model,\n",
        "    tokenizer = tokenizer_quest\n",
        "    )\n",
        "\n",
        "quest(\n",
        "    'question' : \"Où habite Amar ? \",\n",
        "    'context' : \"Amar habite à Paris.\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ_xS0dptpqz",
        "colab_type": "text"
      },
      "source": [
        "#### Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOUfCBs2toJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWXE8HxOGkDH",
        "colab_type": "text"
      },
      "source": [
        "#### Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBxn6P_KGKkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extraction = pipeline(\n",
        "    \"feature-extraction\",\n",
        "    model = model_camembert,\n",
        "    tokenizer = tokenizer_camembert\n",
        "    )\n",
        "\n",
        "feature_extraction(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyOPz8ueX8XB",
        "colab_type": "text"
      },
      "source": [
        "#### Extract All-layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3BMWHCdVUy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
        "labels = torch.tensor([1] * input_ids.size(1)).unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntWY-sYzfjDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs_camembert = model(input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lru2I3GmXoaA",
        "colab_type": "code",
        "outputId": "76ebf8bb-e6e7-402f-cc2e-8345730b41cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "outputs_cammebert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 20.6235,  -4.2011,   6.8420,  ...,  -5.7573,  -3.1165,   1.1391],\n",
              "          [  2.6217,  -5.2430,  17.5290,  ..., -14.2041,  -2.4229,   0.8586],\n",
              "          [ -0.1691,  -9.8924,   1.8213,  ..., -22.9433, -11.8068,  -1.9409],\n",
              "          ...,\n",
              "          [ -0.6569, -10.2129,  -0.5032,  ...,  -7.7102, -10.5380,   1.3649],\n",
              "          [ -1.6542,  -4.3773,   2.8810,  ...,  -7.5383,  -3.0471,  -3.1600],\n",
              "          [  6.3686,  -5.1610,  23.3708,  ...,  -7.9306,  -5.1287,   1.9971]]],\n",
              "        grad_fn=<AddBackward0>),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhprqb6qd6jN",
        "colab_type": "text"
      },
      "source": [
        "## FlauBERT\n",
        "### Ne fonctionne pas pour le moment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihcDvmk8Vo1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import FlaubertModel, AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "flaubert = \"flaubert-large-cased\"\n",
        "\n",
        "tokenizer_flaubert = AutoTokenizer.from_pretrained(flaubert)\n",
        "model_flaubert = AutoModelWithLMHead.from_pretrained(flaubert)\n",
        "\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model = flaubert,\n",
        "    tokenizer = flaubert\n",
        ")\n",
        "\n",
        "fill_mask(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jt446DKKJhn",
        "colab_type": "text"
      },
      "source": [
        "### Flaubert : essai 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5MrIfeKhFO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "from transformers import FlaubertModel, FlaubertTokenizer\n",
        "\n",
        "# Choose among ['flaubert-small-cased', 'flaubert-base-uncased', 'flaubert-base-cased', 'flaubert-large-cased']\n",
        "modelname = 'flaubert-base-cased' \n",
        "\n",
        "# Load pretrained model and tokenizer\n",
        "flaubert, log = FlaubertModel.from_pretrained(modelname, output_loading_info=True)\n",
        "flaubert_tokenizer = FlaubertTokenizer.from_pretrained(modelname, do_lowercase=False)\n",
        "# do_lowercase=False if using cased models, True if using uncased ones\n",
        "\n",
        "sentence = \"Le camembert c'est <mask>.\"\n",
        "token_ids = torch.tensor([flaubert_tokenizer.encode(sentence)])\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model = flaubert,\n",
        "    tokenizer = flaubert_tokenizer\n",
        ")\n",
        "\n",
        "fill_mask(sentence)\n",
        "\n",
        "#last_layer = flaubert(token_ids)[0]\n",
        "#print(last_layer.shape)\n",
        "# torch.Size([1, 8, 768])  -> (batch size x number of tokens x embedding dimension)\n",
        "\n",
        "# The BERT [CLS] token correspond to the first hidden state of the last layer\n",
        "#cls_embedding = last_layer[:, 0, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vdeiAQpSQgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}